{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c991e42",
   "metadata": {},
   "source": [
    "\n",
    "#  US Accidents: Batch-Wise Data Processing & Severity Prediction  \n",
    "\n",
    "## Summary  \n",
    "The **US Accidents dataset** (~7.7M rows, 2016â€“2023) is one of the largest open traffic accident datasets.  \n",
    "A key challenge is that the dataset is **too large to process in memory at once**.  \n",
    "\n",
    "To solve this, I designed a **batch-wise machine learning pipeline** using `chunksize` and `partial_fit`.  \n",
    "This approach mimics real-world big data workflows and shows ability to handle **scalability challenges**.  \n",
    " \n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6b6376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# important libaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "import folium\n",
    "import networkx as nx\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, roc_auc_score, roc_curve,balanced_accuracy_score,precision_recall_curve,average_precision_score, precision_score,recall_score, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723c7cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_path = \"/Users/satishmudrakola/.cache/kagglehub/datasets/sobhanmoosavi/us-accidents/versions/13\"\n",
    "print(os.listdir(data_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888496cb",
   "metadata": {},
   "source": [
    "## 2. Data Loading (Batch-Wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea15e29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset in chunks\n",
    "file_path = \"/Users/satishmudrakola/.cache/kagglehub/datasets/sobhanmoosavi/us-accidents/versions/13/US_Accidents_March23.csv\"\n",
    "\n",
    "# Read the dataset\n",
    "chunksize = 100000\n",
    "data_iter = pd.read_csv(file_path, chunksize=chunksize)\n",
    "df = next(data_iter)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90abc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8774d943",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eeebd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58e298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cheacking the missing values\n",
    "missing_value_counts = df.isnull().sum()\n",
    "missing_value_counts[:46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f549bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentance of missing values\n",
    "total_cols = np.prod(df.shape)\n",
    "total_missing = missing_value_counts.sum()\n",
    "missing_values_per = (total_missing/total_cols )* 100\n",
    "print(f'Total percent of data that is missing {missing_values_per:2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c920b8e6",
   "metadata": {},
   "source": [
    "### The dataset contains about 9% missing values in total.\n",
    "\n",
    "However, the missingness is not evenly distributed: while most columns have little or no missing data, a few features are severely affected (very high proportion of NaNs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c765e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the missing %  values for each cols \n",
    "missing_per_col = (missing_value_counts / len(df)) * 100\n",
    "missing_per_col = missing_per_col[missing_per_col > 0].sort_values(ascending=False)\n",
    "missing_per_col.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bb29bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the missing values\n",
    "missing_per_col.plot(kind='bar', figsize=(12,6))\n",
    "plt.title(\"Percentage of Missing Values per Column\")\n",
    "plt.ylabel(\"Missing %\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e978384f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# memeroy usage of the data\n",
    "df.memory_usage(deep=True).sum() / 1024**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb394be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f145485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate categorical and numerical columns\n",
    "cat_cols = df.select_dtypes(include='object').columns\n",
    "num_cols = df.select_dtypes(exclude='object').columns\n",
    "\n",
    "print(\"Categorical columns and their unique values:\")\n",
    "print(\"*\" * 30)\n",
    "for col in cat_cols:\n",
    "    print(f\"{col}: {df[col].nunique()} unique values\")\n",
    "\n",
    "print(\"*\" * 30)\n",
    "print(\"\\nNumerical columns:\")\n",
    "print(list(num_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e4eec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class balance\n",
    "df['Severity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671fd055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking all the unique values for categorical columns\n",
    "for col in cat_cols:\n",
    "    print(f\"\\nColumn: {col}\")\n",
    "    print(f\"Unique values: {df[col].nunique()}\")\n",
    "    print(\"Top most frequent values:\")\n",
    "    print(df[col].value_counts().head(5))\n",
    "    print(\"*\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a487b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking all the unique values for numeric columns\n",
    "for col in num_cols:\n",
    "    print(f\"\\nColumn: {col}\")\n",
    "    print(f\"Unique values: {df[col].nunique()}\")\n",
    "    print(\"Top most frequent values:\")\n",
    "    print(df[col].value_counts().head(5))\n",
    "    print(\"*\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a02fd9f",
   "metadata": {},
   "source": [
    "# Data Loading and Inspection Analysis\n",
    "\n",
    "\n",
    "The dataset was loaded and inspected for structural issues before analysis. Key steps included:\n",
    "\n",
    "- **Initial Inspection:** Verified dataset shape, column names, and data types.  \n",
    "- **Duplicates:** Checked and removed duplicate records to avoid bias.  \n",
    "- **Data Types:** Converted relevant columns into appropriate datetime objects.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e7a1ca",
   "metadata": {},
   "source": [
    "# Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d6e1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns \n",
    "cols_to_drop = ['ID', 'Description', 'Street', 'Zipcode', 'Weather_Timestamp',\n",
    "                'End_Lat', 'End_Lng', 'Wind_Chill(F)', 'Country']\n",
    "df.drop(columns=cols_to_drop, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7178596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing numeric values\n",
    "numeric_impute_median = ['Precipitation(in)', 'Wind_Speed(mph)', 'Visibility(mi)']\n",
    "for col in numeric_impute_median:\n",
    "    df[col].fillna(df[col].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a3fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing categorical values\n",
    "categorical_impute_mode = ['Wind_Direction']\n",
    "for col in categorical_impute_mode:\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694f9006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wind_Direction: unify \"CALM\" / \"Calm\"\n",
    "df['Wind_Direction'] = df['Wind_Direction'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb347218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather_Condition: group into main buckets\n",
    "def normalize_weather(x):\n",
    "    if pd.isnull(x):\n",
    "        return 'Unknown'\n",
    "    x = x.lower()\n",
    "    if any(word in x for word in ['clear', 'fair']):\n",
    "        return 'Clear'\n",
    "    elif any(word in x for word in ['cloud', 'overcast', 'partly']):\n",
    "        return 'Cloudy'\n",
    "    elif any(word in x for word in ['rain', 'drizzle', 'shower', 'thunder']):\n",
    "        return 'Rain'\n",
    "    elif any(word in x for word in ['snow', 'sleet', 'flurries']):\n",
    "        return 'Snow'\n",
    "    elif any(word in x for word in ['fog', 'mist', 'haze']):\n",
    "        return 'Fog'\n",
    "    else:\n",
    "        return 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198ff149",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Weather_Condition'] = df['Weather_Condition'].apply(normalize_weather)\n",
    "df['Weather_Condition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0655c1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32dbded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling Remaining Missing Values\n",
    "#Fill small missing values in categorical columns\n",
    "df['City'].fillna('Unknown', inplace=True)\n",
    "df['Timezone'].fillna('Unknown', inplace=True)\n",
    "df['Airport_Code'].fillna('Unknown', inplace=True)\n",
    "df['Sunrise_Sunset'].fillna('Unknown', inplace=True)\n",
    "df['Civil_Twilight'].fillna('Unknown', inplace=True)\n",
    "df['Nautical_Twilight'].fillna('Unknown', inplace=True)\n",
    "df['Astronomical_Twilight'].fillna('Unknown', inplace=True)\n",
    "\n",
    "#Impute missing numeric weather features with median\n",
    "weather_numeric = ['Temperature(F)', 'Humidity(%)', 'Pressure(in)']\n",
    "for col in weather_numeric:\n",
    "    df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "#Once again Verifying all missing values are handleded or not\n",
    "print(\"Missing values after imputation:\")\n",
    "print(df.isnull().sum().sum())  # total count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2067d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outliers detection\n",
    "num_cols = df.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "num_cols.remove('Severity')  # exclude target\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "for i, col in enumerate(num_cols):\n",
    "    plt.subplot(len(num_cols)//3 + 1, 3, i+1)\n",
    "    sns.boxplot(y=df[col])\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8c7d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "for i, col in enumerate(num_cols):\n",
    "    plt.subplot(len(num_cols)//3 + 1, 3, i+1)\n",
    "    sns.histplot(df[col], kde=True, bins=50)\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8421a13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capping method\n",
    "for col in num_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    df[col] = np.where(df[col] < lower, lower, df[col])\n",
    "    df[col] = np.where(df[col] > upper, upper, df[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32686710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize After Outlier Handling\n",
    "plt.figure(figsize=(15,8))\n",
    "for i, col in enumerate(num_cols):\n",
    "    plt.subplot(len(num_cols)//3 + 1, 3, i+1)\n",
    "    sns.boxplot(y=df[col])\n",
    "    plt.title(f\"{col} (after handling)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cce4692",
   "metadata": {},
   "source": [
    "## Data Handling & Preprocessing\n",
    "\n",
    "A high-quality dataset is the foundation of any robust machine learning pipeline.  \n",
    "To ensure integrity and reliability, multiple stages of preprocessing were carried out:\n",
    "\n",
    "### Missing Value Treatment\n",
    "- **Numeric features** â†’ Imputed using statistical measures (**mean/median**, depending on distribution).  \n",
    "- **Categorical features** â†’ Imputed using the most frequent category (**mode**).  \n",
    "- **Remaining missing values** â†’ Re-examined and handled systematically to prevent data leakage or bias.  \n",
    "\n",
    "### Outlier Detection & Treatment\n",
    "- Applied the **Interquartile Range (IQR)** method to identify and cap extreme values in key numerical columns.  \n",
    "- This ensured that unusual records (e.g., abnormal traffic counts or weather readings) did not distort model learning.  \n",
    "\n",
    "---\n",
    "\n",
    "**Insight:**  \n",
    "After these steps, the dataset became consistent, balanced in scale, and ready for downstream modeling.  \n",
    "\n",
    "**Takeaway:**  \n",
    "A structured preprocessing pipeline â€” combining imputation and outlier treatment â€” transformed raw accident logs into reliable, high-quality training data, reducing noise and improving model robustness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a5af42",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20378fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target Variable Analysis\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='Severity', data=df, palette=\"coolwarm\")\n",
    "plt.title('Accident Severity Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Percentage distribution\n",
    "severity_percent = df['Severity'].value_counts(normalize=True) * 100\n",
    "print(\"Severity percentage distribution:\\n\", severity_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a7c957",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numerical Feature Distributions\n",
    "num_cols = df.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "num_cols.remove('Severity')\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "for i, col in enumerate(num_cols):\n",
    "    plt.subplot(len(num_cols)//3 + 1, 3, i+1)\n",
    "    sns.histplot(df[col], kde=True, bins=50, color='skyblue')\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e86a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for violin plots\n",
    "def plot_violin(df, feature, target=\"Severity\"):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    sns.violinplot(\n",
    "        x=df[target].astype(str),\n",
    "        y=df[feature],\n",
    "        palette=\"coolwarm\",\n",
    "        inner=\"quartile\"\n",
    "    )\n",
    "    plt.title(f\"{feature} vs {target}\", fontsize=14, pad=10)\n",
    "    plt.xlabel(\"Accident Severity\")\n",
    "    plt.ylabel(feature)\n",
    "    plt.show()\n",
    "\n",
    "features = [\"Distance(mi)\",\"Wind_Speed(mph)\"]\n",
    "\n",
    "for f in features:\n",
    "    plot_violin(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaab7b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Start_Time to datetime first\n",
    "df['Start_Time'] = pd.to_datetime(df['Start_Time'], errors='coerce')\n",
    "\n",
    "# Extract time-based features BEFORE encoding\n",
    "df['Hour'] = df['Start_Time'].dt.hour\n",
    "df['DayOfWeek'] = df['Start_Time'].dt.dayofweek\n",
    "df['Month'] = df['Start_Time'].dt.month\n",
    "df['Weekend'] = df['DayOfWeek'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "#Accidents by Hour\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(x='Hour', data=df, palette='coolwarm', order=sorted(df['Hour'].unique()))\n",
    "plt.title('Accidents by Hour of Day')\n",
    "plt.xlabel(\"Hour of Day (0=Midnight)\")\n",
    "plt.ylabel(\"Accident Count\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Accidents by Day of Week\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(x='DayOfWeek', data=df, palette='viridis')\n",
    "plt.title(\"Accidents by Day of Week (0=Mon, 6=Sun)\")\n",
    "plt.xlabel(\"Day of Week\")\n",
    "plt.ylabel(\"Accident Count\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Accidents by Month\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(x='Month', data=df, palette='magma')\n",
    "plt.title(\"Accidents by Month\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Accident Count\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Weekday vs Weekend\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='Weekend', data=df, palette='Set2')\n",
    "plt.title(\"Accidents: Weekday vs Weekend\")\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Accident Count\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7237bd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap: Severity by Hour & DayOfWeek\n",
    "hour_day = df.groupby(['Hour','DayOfWeek'])['Severity'].mean().unstack()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(hour_day, cmap='coolwarm', annot=True, fmt=\".2f\", cbar_kws={'label': 'Avg Severity'})\n",
    "plt.title(\"Average Severity by Hour & Day of Week\")\n",
    "plt.xlabel(\"Day of Week (0=Mon, 6=Sun)\")\n",
    "plt.ylabel(\"Hour of Day\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0490fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geospatial Clusters\n",
    "# Sample for performance\n",
    "sample_df = df[['Start_Lat','Start_Lng']].dropna().sample(10000)\n",
    "kmeans = KMeans(n_clusters=6, random_state=42).fit(sample_df)\n",
    "sample_df['Cluster'] = kmeans.labels_\n",
    "\n",
    "m = folium.Map(location=[39.8283, -98.5795], zoom_start=4)\n",
    "for _, row in sample_df.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['Start_Lat'], row['Start_Lng']],\n",
    "        radius=3,\n",
    "        color=f\"C{row['Cluster']}\",\n",
    "        fill=True,\n",
    "        fill_opacity=0.7\n",
    "    ).add_to(m)\n",
    "m  # Interactive map in notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61bd2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation network\n",
    "numeric_df = df.select_dtypes(include=['float64', 'int64'])\n",
    "corr = numeric_df.corr()\n",
    "\n",
    "#Build edges based on correlation threshold\n",
    "edges = [\n",
    "    (i, j, corr.loc[i, j]) \n",
    "    for i in corr.columns \n",
    "    for j in corr.columns \n",
    "    if i != j and abs(corr.loc[i, j]) > 0.3\n",
    "]\n",
    "\n",
    "#Create graph\n",
    "G = nx.Graph()\n",
    "for i, j, w in edges:\n",
    "    G.add_edge(i, j, weight=w)\n",
    "\n",
    "#Plot correlation network\n",
    "plt.figure(figsize=(12, 12))\n",
    "pos = nx.spring_layout(G, k=0.5, seed=42)\n",
    "nx.draw(G, pos, with_labels=True, \n",
    "        node_size=2000, \n",
    "        node_color='skyblue', \n",
    "        edge_color='gray', \n",
    "        font_size=10)\n",
    "plt.title(\"Correlation Network of Numeric Features\", fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36412cb7",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "To extract meaningful insights, multiple stages of exploratory analysis were carried out. The findings are structured below:\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Target Variable Analysis\n",
    "- The dataset shows **imbalanced severity classes**.  \n",
    "- **Severity 2** accidents dominate, making up the majority of records, followed by **Severity 3**.  \n",
    "- **Severity 1** and **Severity 4** are comparatively rare.  \n",
    "- This imbalance must be addressed during modeling (e.g., resampling or class-weighting).  \n",
    "\n",
    "---\n",
    "\n",
    "## 2. Feature vs Target Analysis\n",
    "- **Violin Plots** revealed how numerical features vary with severity:\n",
    "  - **Distance (mi):** Higher severity accidents are often linked with longer distances.  \n",
    "  - **Wind Speed (mph):** Extreme wind speeds (both calm and high) can increase severity.  \n",
    "  - **Hour of Day:** Severity patterns shift depending on time (late-night vs rush-hour).  \n",
    "\n",
    "---\n",
    "\n",
    "## 3. Temporal Trends\n",
    "- **Accidents by Hour:** Clear peaks during **rush hours (7â€“9 AM, 4â€“7 PM)**.  \n",
    "- **Accidents by Month:** Seasonal variation observed, with higher accident frequency in **winter months**, likely due to weather.  \n",
    "- **Weekday vs Weekend:** Weekdays show significantly more accidents compared to weekends.  \n",
    "- **Severity Heatmap (Hour Ã— Day of Week):**  \n",
    "  - Weekday mornings and evenings show the **highest severity concentration**.  \n",
    "  - Late-night accidents on weekends also lean toward higher severity.  \n",
    "\n",
    "---\n",
    "\n",
    "## 4. Geospatial Analysis\n",
    "- Using **Folium maps**, geospatial clustering highlighted accident hotspots.  \n",
    "- **Eastern USA (East Coast)** shows **much higher accident density** compared to the West.  \n",
    "- Clusters are especially concentrated around **urban and densely populated areas** (e.g., Northeast Corridor, California highways).  \n",
    "\n",
    "---\n",
    "\n",
    "## 5. Correlation & Feature Relationships\n",
    "- **Correlation Heatmap:** Checked dependencies among numerical features.  \n",
    "- **Correlation Network:** Visualized groups of strongly connected features, flagging redundancy.  \n",
    "- While most features had low correlation, a few weather-related and traffic-related features showed moderate association.  \n",
    "\n",
    "---\n",
    "\n",
    "###  Key Insights\n",
    "1. **Severity Imbalance:** Severity 2 dominates, requiring balancing techniques.  \n",
    "2. **Temporal Effects:** Rush hours and weekdays drive accident frequency, with severity spikes at night.  \n",
    "3. **Geospatial Distribution:** Eastern US (especially urban regions) has higher accident density than the West.  \n",
    "4. **Feature Patterns:** Distance and environmental conditions (wind, time of day) influence accident severity.  \n",
    "5. **Feature Correlations:** Minimal multicollinearity overall, with some weather-related overlaps.  \n",
    "\n",
    "---\n",
    "\n",
    "###  Takeaway\n",
    "The EDA confirms that accident severity is shaped by **when** (time), **where** (geospatial patterns), and **environmental conditions**.  \n",
    "By combining violin plots, time-series analysis, folium maps, and correlation networks, we established a multi-perspective understanding of accident dynamics in the US.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640dfc0d",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130a0c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical(df, high_card_threshold=50, top_n=10, use_binary_encoding=True):\n",
    "    \"\"\"\n",
    "    Encode categorical features:\n",
    "    - High-cardinality -> Label or Binary encoding\n",
    "    - Low-cardinality -> Top-N One-Hot\n",
    "    - Binary categorical -> 0/1\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # Detect categorical columns\n",
    "    cat_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "    print(f\"Categorical columns: {cat_cols}\")\n",
    "\n",
    "    # Separate binary, low, high cardinality\n",
    "    binary_cols = [col for col in cat_cols if df[col].nunique() == 2]\n",
    "    high_card_cols = [col for col in cat_cols if df[col].nunique() > high_card_threshold]\n",
    "    low_card_cols = [col for col in cat_cols if 2 < df[col].nunique() <= high_card_threshold]\n",
    "\n",
    "    print(f\"Binary cols: {binary_cols}\")\n",
    "    print(f\"Low-cardinality cols: {low_card_cols}\")\n",
    "    print(f\"High-cardinality cols: {high_card_cols}\")\n",
    "\n",
    "    # --------------------------\n",
    "    # Binary cols -> map to 0/1\n",
    "    for col in binary_cols:\n",
    "        df[col] = df[col].astype('category').cat.codes\n",
    "\n",
    "    # --------------------------\n",
    "    # Low-cardinality -> Top-N One-Hot\n",
    "    for col in low_card_cols:\n",
    "        top_values = df[col].value_counts().nlargest(top_n).index\n",
    "        df[col] = df[col].apply(lambda x: x if x in top_values else 'Other')\n",
    "    df = pd.get_dummies(df, columns=low_card_cols, drop_first=True)\n",
    "\n",
    "    # --------------------------\n",
    "    # High-cardinality\n",
    "    if use_binary_encoding and high_card_cols:\n",
    "        encoder = ce.BinaryEncoder(cols=high_card_cols)\n",
    "        df = encoder.fit_transform(df)\n",
    "    else:\n",
    "        for col in high_card_cols:\n",
    "            df[col] = LabelEncoder().fit_transform(df[col].astype(str))\n",
    "\n",
    "    print(f\"Shape after encoding: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "# ----------------------\n",
    "# Example usage\n",
    "df_encoded = encode_categorical(df, high_card_threshold=50, top_n=10, use_binary_encoding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc927a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time-based Enrichment\n",
    "df_encoded['Rush_Hour'] = df['Hour'].apply(lambda x: 1 if (7 <= x <= 9) or (16 <= x <= 19) else 0)\n",
    "df_encoded['Season'] = df['Month'].map({12:'Winter',1:'Winter',2:'Winter',\n",
    "                                3:'Spring',4:'Spring',5:'Spring',\n",
    "                                6:'Summer',7:'Summer',8:'Summer',\n",
    "                                9:'Fall',10:'Fall',11:'Fall'})\n",
    "\n",
    "df_encoded['Season']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07276bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded['Rush_Hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4a6ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d638324",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Road/Infrastructure Features\n",
    "infra_cols = ['Amenity','Bump','Crossing','Give_Way','Junction','No_Exit',\n",
    "              'Railway','Roundabout','Station','Stop','Traffic_Calming','Traffic_Signal','Turning_Loop']\n",
    "df_encoded['Infra_Risk_Score'] = df[infra_cols].sum(axis=1)\n",
    "\n",
    "df_encoded['Infra_Risk_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7282e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adverse Weather: Rain, Snow, Fog, etc.\n",
    "df_encoded['Adverse_Weather'] = df_encoded[['Weather_Condition_Rain', \n",
    "                                            'Weather_Condition_Snow',\n",
    "                                            'Weather_Condition_Fog']].sum(axis=1)\n",
    "df_encoded['Visibility_Precip'] = df_encoded['Visibility(mi)'] * (df_encoded['Precipitation(in)'] + 1)\n",
    "df_encoded['Adverse_Weather']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ebd9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded['Visibility_Precip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b95bae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geospatial Features\n",
    "coords = df_encoded[['Start_Lat','Start_Lng']]\n",
    "kmeans = KMeans(n_clusters=20, random_state=42)\n",
    "df_encoded['Accident_Cluster'] = kmeans.fit_predict(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670aca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency-Based Features\n",
    "df_encoded['City_Freq'] = df_encoded[['City_0','City_1','City_2','City_3','City_4',\n",
    "                                      'City_5','City_6','City_7','City_8','City_9']].sum(axis=1)\n",
    "df_encoded['City_Freq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8cb4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "season_dummies = pd.get_dummies(df_encoded['Season'], prefix='Season')\n",
    "df_encoded = pd.concat([df_encoded.drop(columns=['Season']), season_dummies], axis=1)\n",
    "df_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16e1d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean columns â†’ convert to int\n",
    "bool_cols = df_encoded.select_dtypes(include='bool').columns.tolist()\n",
    "df_encoded[bool_cols] = df_encoded[bool_cols].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7872d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric columns\n",
    "num_cols = df_encoded.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "# Remove target if included\n",
    "target = 'Severity'\n",
    "if target in num_cols:\n",
    "    num_cols.remove(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3419bc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target\n",
    "target = 'Severity'\n",
    "\n",
    "# Current feature set\n",
    "X = df.drop(columns=[target, 'Start_Time'])  # drop original datetime & target\n",
    "y = df[target]\n",
    "\n",
    "# Numeric columns\n",
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Categorical columns\n",
    "cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(\"Numeric columns:\", num_cols[:5], \"...\")\n",
    "print(\"Categorical columns:\", cat_cols[:5], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa5792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bulding a Preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690492b3",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "To enrich the dataset and enhance predictive power, several feature engineering techniques were applied:\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Temporal Features\n",
    "- Converted **Start_Time** into a datetime object.\n",
    "- Derived granular time-based features:\n",
    "  - **Hour** (0â€“23)  \n",
    "  - **DayOfWeek** (0â€“6)  \n",
    "  - **Month** (1â€“12)  \n",
    "- Constructed domain-driven features:\n",
    "  - **Rush_Hour:** Binary flag for morning/evening rush periods (7â€“9 AM, 4â€“7 PM).  \n",
    "  - **Season:** Mapped months into categorical seasons (Winter, Spring, Summer, Fall).\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Categorical Encoding\n",
    "- Developed a flexible encoding function:\n",
    "  - **High-cardinality features:** Label or binary encoding.  \n",
    "  - **Low-cardinality features:** One-hot encoding (Top-N categories preserved).  \n",
    "- Example: **City** frequencies were retained using a **frequency-based representation**.  \n",
    "\n",
    "---\n",
    "\n",
    "## 3. Road & Infrastructure Features\n",
    "- Engineered an **Infrastructure Risk Score** by summing binary indicators such as:  \n",
    "  *Amenity, Crossing, Junction, Traffic Signal, Stop, Railway,* etc.  \n",
    "- This consolidated multiple sparse features into a single interpretable metric.  \n",
    "\n",
    "---\n",
    "\n",
    "## 4. Geospatial Features\n",
    "- Applied **KMeans clustering** on accident coordinates (`Start_Lat`, `Start_Lng`).  \n",
    "- Created a new feature **Accident_Cluster** to capture regional accident patterns.  \n",
    "\n",
    "---\n",
    "\n",
    "## 5. Frequency-Based Features\n",
    "- Encoded high-frequency categorical attributes by aggregating their top-N dummy variables.  \n",
    "- Example: **City_Freq** was computed from top 10 most common cities.  \n",
    "\n",
    "---\n",
    "\n",
    "## 6. Final Dataset Construction\n",
    "- Dropped non-predictive fields such as raw `Start_Time` and the target column.  \n",
    "- Prepared feature matrix **X** and target **y = Severity**.  \n",
    "- Final dataset included a **blend of raw, derived, and encoded features**, ensuring both interpretability and predictive richness.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Takeaways\n",
    "- **Temporal context** (hour, day, season) provides strong predictive signals.  \n",
    "- **Domain-driven features** like Rush Hour, Infrastructure Risk, and Clusters improve interpretability.  \n",
    "- **Encoding strategies** prevented high-cardinality features (e.g., City) from overwhelming the model.  \n",
    "- Feature engineering transformed the dataset from a flat accident log into a structured, multi-dimensional representation â€” critical for model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9e5f67",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534ecb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split features and target\n",
    "X = df_encoded.drop(columns=['Severity', 'Start_Time'], errors='ignore')\n",
    "y = df_encoded['Severity']\n",
    "\n",
    "#Train/Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "#Scale numeric features (optional)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "num_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "scaler = StandardScaler()\n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "X_test[num_cols] = scaler.transform(X_test[num_cols])\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "print(\"Any missing values in train:\", X_train.isnull().sum().sum())\n",
    "print(\"Any missing values in test:\", X_test.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15a4a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify current columns in X\n",
    "print(X_train.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49815f2e",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ce8348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model dictionary\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        max_iter=2000, solver=\"lbfgs\", multi_class=\"multinomial\", random_state=42\n",
    "    ),\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        n_estimators=200, random_state=42, n_jobs=-1\n",
    "    ),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(\n",
    "        n_estimators=200, random_state=42\n",
    "    ),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        objective=\"multi:softmax\",\n",
    "        num_class=4,\n",
    "        eval_metric=\"mlogloss\",\n",
    "        random_state=42,\n",
    "        n_estimators=300,\n",
    "        use_label_encoder=False  # backward-compatible\n",
    "    ),\n",
    "    \"SVM (Linear)\": LinearSVC(\n",
    "        random_state=42, max_iter=5000\n",
    "    )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaca282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift severity labels to start from 0\n",
    "y_train -= 1\n",
    "y_test  -= 1\n",
    "\n",
    "print(\"Unique labels in train:\", y_train.unique())\n",
    "print(\"Unique labels in test:\", y_test.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c318d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already split your data into X_train, X_test, y_train, y_test\n",
    "\n",
    "# Combine train and test indices\n",
    "used_indices = X_train.index.union(X_test.index)\n",
    "\n",
    "# Remaining/unseen records\n",
    "X_remaining = df.drop(used_indices).drop('Severity', axis=1)\n",
    "remaining_df = df.drop(used_indices).copy()\n",
    "\n",
    "print(f\"Number of remaining/unseen records: {len(X_remaining)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9ad507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=200, random_state=42),\n",
    "    \"xgb_model\" : XGBClassifier(\n",
    "    objective='multi:softmax',  \n",
    "    num_class=4,                \n",
    "    eval_metric='mlogloss',\n",
    "    random_state=4),\n",
    "    \"svm_model\" : LinearSVC(random_state=42, max_iter=5000)\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# For ROC curve plotting (binary only)\n",
    "plt.figure(figsize=(8,6))\n",
    "binary_target = len(y.unique()) == 2\n",
    "\n",
    "for name, clf in models.items():\n",
    "    print(f\"\\n--------- {name} --------- \")\n",
    "    \n",
    "    # Train model\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Accuracy & F1\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    results[name] = (acc, f1)\n",
    "    \n",
    "    # ROC-AUC (only if binary)\n",
    "    if binary_target:\n",
    "        y_prob = clf.predict_proba(X_test)[:,1]\n",
    "        roc_auc = roc_auc_score((y_test==y_test.unique()[1]).astype(int), y_prob)\n",
    "        print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "        \n",
    "        # Plot ROC curve\n",
    "        fpr, tpr, _ = roc_curve((y_test==y_test.unique()[1]).astype(int), y_prob)\n",
    "        plt.plot(fpr, tpr, label=f\"{name} (AUC={roc_auc:.2f})\")\n",
    "\n",
    "# Showing ROC curve (binary only)\n",
    "if binary_target:\n",
    "    plt.plot([0,1], [0,1], 'k--')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Overview\n",
    "print(\"\\n -------- Model Comparison (Accuracy / F1)  -------- \")\n",
    "for k, v in results.items():\n",
    "    print(f\"{k}: Accuracy={v[0]:.4f}, F1={v[1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e725356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model results \n",
    "results = {\n",
    "    \"Model\": [\"Logistic Regression\", \"Support Vector Machine\", \n",
    "              \"Gradient Boosting\", \"Random Forest\", \"XGBoost\"],\n",
    "    \"Accuracy\": [0.6818, 0.6809, 0.8498, 0.8985, 0.9124],\n",
    "    \"F1 Score\": [0.6818, 0.6809, 0.8498, 0.8981, 0.9120]\n",
    "}\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Plot leaderboard\n",
    "plt.figure(figsize=(8,5))\n",
    "df_results.set_index(\"Model\")[[\"Accuracy\", \"F1 Score\"]].plot(\n",
    "    kind=\"bar\", figsize=(10,6), width=0.7\n",
    ")\n",
    "plt.title(\"Model Leaderboard (Accuracy & F1 Score)\", fontsize=14)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.6, 1.0)\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933d257b",
   "metadata": {},
   "source": [
    "### Insight: Ensemble methods, particularly XGBoost, excel in handling structured, high-dimensional accident data, making them ideal for severity prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e65c4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Update your models dictionary to include XGBoost\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "}\n",
    "\n",
    "# Define k-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Random Forest CV\n",
    "rf_scores = cross_val_score(models['Random Forest'], X_train, y_train, cv=kf, scoring='accuracy')\n",
    "\n",
    "print(\"Cross-Validation Results for Random Forest\")\n",
    "print(f\"Fold-wise Accuracies : {rf_scores}\")\n",
    "print(f\"Mean CV Accuracy     : {rf_scores.mean():.4f}\")\n",
    "print(f\"Standard Deviation   : {rf_scores.std():.4f}\")\n",
    "\n",
    "print(\"=========================================\")\n",
    "# XGBoost CV\n",
    "xgb_scores = cross_val_score(models['XGBoost'], X_train, y_train, cv=kf, scoring='accuracy')\n",
    "\n",
    "print(\"Cross-Validation Results for XGBoost\")\n",
    "print(f\"Fold-wise Accuracies : {xgb_scores}\")\n",
    "print(f\"Mean CV Accuracy     : {xgb_scores.mean():.4f}\")\n",
    "print(f\"Standard Deviation   : {xgb_scores.std():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0409bb1d",
   "metadata": {},
   "source": [
    "- **Random Forest** and **XGBoost** perform very similarly, both in cross-validation and on unseen test data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615fc8f9",
   "metadata": {},
   "source": [
    "# Overview of Models and Evalution Matirx\n",
    "## Models Applied\n",
    "- **Logistic Regression:** Established as a baseline for interpretability.  \n",
    "- **Random Forest:** Captured non-linear feature interactions and ranked feature importance.  \n",
    "- **XGBoost:** Applied as a boosting model to maximize predictive accuracy.  \n",
    "- **Other Models (if applied):** Compared performance across additional algorithms.\n",
    "\n",
    "---\n",
    "\n",
    "## Evaluation Metrics\n",
    "- **Accuracy:** Overall correctness of predictions.  \n",
    "- **Precision, Recall, F1-score:** Evaluated class-level performance, critical due to severity imbalance.  \n",
    "- **Confusion Matrix:** Provided detailed breakdown of misclassifications across severity levels.  \n",
    "- **ROC-AUC:** Assessed discriminatory power across models.\n",
    "\n",
    "### Insights\n",
    "- **XGBoost** outperformed all other models, achieving the best balance of accuracy and recall.  \n",
    "- **Random Forest** offered strong performance with added interpretability via feature importance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296a0771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance (Random Forest & XGBoost)\n",
    "top_models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        objective='multi:softmax',\n",
    "        num_class=4,\n",
    "        eval_metric='mlogloss',\n",
    "        n_estimators=300,\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "for name, model in top_models.items():\n",
    "    print(f\"\\n=== {name} Feature Importance ===\")\n",
    "    \n",
    "    # Fit model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Extract importance\n",
    "    importances = model.feature_importances_\n",
    "    features = X_train.columns\n",
    "    fi_df = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'Importance': importances\n",
    "    }).sort_values('Importance', ascending=False).head(15)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.barh(fi_df['Feature'], fi_df['Importance'], color='blue')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(f\"Top 15 Features - {name}\")\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb23c542",
   "metadata": {},
   "source": [
    "### Feature Importance Analysis: Random Forest & XGBoost\n",
    "\n",
    "To identify which features most influence accident severity, computed**feature importance** using our two top-performing models:  \n",
    "\n",
    "1. **Random Forest** â€“ evaluates feature impact based on tree splits across all trees.  \n",
    "2. **XGBoost** â€“ gradient boosting method that ranks features by their contribution to model performance.  \n",
    "\n",
    "For each model, we display the **top most important features** in a horizontal bar chart.  \n",
    "\n",
    "These plots provide insights into the **key predictors of accident severity** and help guide feature selection and risk mitigation strategies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45580d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision-Recall Curve\n",
    "# Binarize test labels for One-vs-Rest\n",
    "classes = sorted(y_test.unique())\n",
    "y_test_bin = label_binarize(y_test, classes=classes)\n",
    "n_classes = y_test_bin.shape[1]\n",
    "for name, clf in models.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(f\"{name} model trained successfully!\")\n",
    "# Get predicted probabilities for Random Forest and XGBoost\n",
    "rf_probs = models['Random Forest'].predict_proba(X_test)\n",
    "xgb_probs = models['XGBoost'].predict_proba(X_test)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Random Forest PR curves\n",
    "for i in range(n_classes):\n",
    "    precision, recall, _ = precision_recall_curve(y_test_bin[:, i], rf_probs[:, i])\n",
    "    plt.plot(recall, precision, label=f\"RF Class {classes[i]}\")\n",
    "\n",
    "# XGBoost PR curves\n",
    "for i in range(n_classes):\n",
    "    precision, recall, _ = precision_recall_curve(y_test_bin[:, i], xgb_probs[:, i])\n",
    "    plt.plot(recall, precision, '--', label=f\"XGB Class {classes[i]}\")\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Multiclass Precision-Recall Curve\")\n",
    "plt.legend(loc=\"lower left\", fontsize=8)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d154ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with actual labels and predictions\n",
    "test_predictions = X_test.copy()  # Start with test features if you want to keep them\n",
    "test_predictions['Actual'] = y_test\n",
    "test_predictions['XGBoost_Pred'] = models['XGBoost'].predict(X_test)\n",
    "\n",
    "# Optional: add predicted probabilities\n",
    "test_predictions['XGBoost_Prob'] = models['XGBoost'].predict_proba(X_test)[:, 1]  # probability for positive class\n",
    "\n",
    "# Save to CSV\n",
    "test_predictions.to_csv('test_predictions.csv', index=False)\n",
    "\n",
    "print(\"Test predictions saved successfully to 'test_predictions.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d90506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "y_pred = models['XGBoost'].predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Balanced Accuracy\n",
    "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Precision, Recall, F1 (macro-averaged for multiclass)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Note: Specificity is not directly defined for multiclass; you can compute it per class if needed\n",
    "# ROC-AUC for multiclass requires predicted probabilities and One-vs-Rest\n",
    "from sklearn.preprocessing import label_binarize\n",
    "y_test_bin = label_binarize(y_test, classes=sorted(y_test.unique()))\n",
    "y_proba = models['XGBoost'].predict_proba(X_test)\n",
    "roc_auc = roc_auc_score(y_test_bin, y_proba, average='macro', multi_class='ovr')\n",
    "\n",
    "\n",
    "print(\"Test Data Mertics: \")\n",
    "print('=='*30)\n",
    "# Store metrics\n",
    "test_metrics = {\n",
    "    \"Accuracy\": accuracy,\n",
    "    \"Balanced Accuracy\": balanced_acc,\n",
    "    \"Precision (macro)\": precision,\n",
    "    \"Recall (macro)\": recall,\n",
    "    \"F1 Score (macro)\": f1,\n",
    "    \"ROC-AUC (macro, OvR)\": roc_auc,\n",
    "\n",
    "    \"Confusion Matrix\": cm\n",
    "}\n",
    "\n",
    "test_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138d52e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize labels for multiclass (One-vs-Rest)\n",
    "classes = sorted(y_test.unique())\n",
    "y_test_bin = label_binarize(y_test, classes=classes)\n",
    "y_proba = models['XGBoost'].predict_proba(X_test)\n",
    "n_classes = y_test_bin.shape[1]\n",
    "\n",
    "# ROC Curve per class\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(n_classes):\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_proba[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f\"Class {classes[i]} (AUC = {roc_auc:.3f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - Test Data\")\n",
    "plt.legend(loc=\"lower right\", fontsize=8)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Precision-Recall Curve per class\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(n_classes):\n",
    "    precision, recall, _ = precision_recall_curve(y_test_bin[:, i], y_proba[:, i])\n",
    "    ap = average_precision_score(y_test_bin[:, i], y_proba[:, i])\n",
    "    plt.plot(recall, precision, label=f\"Class {classes[i]} (AP = {ap:.3f})\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve - Test Data\")\n",
    "plt.legend(loc=\"lower right\", fontsize=8)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458e76c2",
   "metadata": {},
   "source": [
    "# Test Set Model Evaluation (ROC & Precision-Recall)\n",
    "\n",
    "Evaluated the final XGBoost model on the **test dataset** using both **ROC curves** and **Precision-Recall (PR) curves** to assess performance for each class.\n",
    "\n",
    "---\n",
    "\n",
    "## ROC Curve\n",
    "\n",
    "- The **ROC curve** shows the model's ability to distinguish each class from the rest (One-vs-Rest).  \n",
    "- **AUC (Area Under Curve)** is reported for each class, indicating discrimination power.  \n",
    "- Higher AUC values (~1.0) indicate better ability to separate that class from others.  \n",
    "- Visual inspection helps identify which classes are more difficult for the model to distinguish.\n",
    "\n",
    "---\n",
    "\n",
    "## Precision-Recall Curve\n",
    "\n",
    "- The **PR curve** highlights the trade-off between **precision** and **recall** for each class.  \n",
    "- **Average Precision (AP)** is reported per class, summarizing the area under each PR curve.  \n",
    "- Particularly useful for **imbalanced classes**, showing how well the model identifies positives.  \n",
    "- Classes with lower AP may require further attention, e.g., class weighting or resampling.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **ROC-AUC values** indicate strong discrimination for most classes.  \n",
    "2. **PR curves** reveal that the model performs very well for majority classes but may struggle with minority classes.  \n",
    "3. These visualizations complement the numeric metrics (accuracy, precision, recall, F1) to give a complete understanding of model performance on the test data.\n",
    "\n",
    "\n",
    "The predictions have been saved to `test_predictions.csv` for further analysis or deployment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539a56b2",
   "metadata": {},
   "source": [
    "### Conclusion & Next Steps\n",
    "\n",
    "This analysis explored the US Accidents dataset with a focus on understanding and predicting accident severity. After rigorous **data cleaning** and **feature engineering**, including temporal (`Hour`, `DayOfWeek`, `Rush_Hour`), environmental (`Weather_Condition`, `Visibility_Precip`), and location-based features, we trained multiple machine learning models. **Random Forest** and **XGBoost** consistently outperformed others, achieving the highest accuracy and F1-scores. Feature importance analysis highlighted that **peak hours, adverse weather conditions, and low visibility** are the strongest predictors of accident severity, confirming domain insights.  \n",
    "\n",
    "**Next Steps & Recommendations:**  \n",
    "-  **Hyperparameter Optimization:** Fine-tune Random Forest and XGBoost to further boost predictive performance.  \n",
    "-  **Class Imbalance Handling:** Apply SMOTE or class-weight adjustments for rare severity classes.  \n",
    "-  **Geospatial Risk Mapping:** Cluster accident locations to identify hotspots and inform preventive measures.  \n",
    "-  **Deployment & Real-Time Prediction:** Integrate the trained pipeline into a dashboard for live accident risk assessment.  \n",
    "-  **Enhanced Feature Engineering:** Incorporate traffic density, road type, and historical accident trends to refine predictions.  \n",
    "\n",
    "This workflow demonstrates a **complete ML pipeline** from raw data to interpretable insights, ready for **real-world application and further experimentation**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
